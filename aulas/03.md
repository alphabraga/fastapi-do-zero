---
title: Configurando o banco de dados e gerenciando migrações com Alembic
description: Criação de um modelo usando SQLAlchemy e migrações
---

# Configurando o Banco de Dados e Gerenciando Migrações com Alembic

---
Objetivos dessa aula:

-  Introdução ao SQLAlchemy e Alembic
-  Instalando SQLAlchemy e Alembic
-  Configurando e criando o banco de dados
-  Criando e localizando tabelas utilizando SQLAlchemy
-  Testando a criação de tabelas
-  Gerenciando migrações do banco de dados com Alembic

??? tip "Caso prefira ver a aula em vídeo"
	![type:video](https://www.youtube.com/embed/u31qwQUeGuM)

[Aula :fontawesome-brands-youtube:](#){ .md-button }
[Slides :fontawesome-solid-file-powerpoint:](https://github.com/dunossauro/fastapi-do-zero/blob/main/slides/pdf/aula_03.pdf){ .md-button }
[Código :fontawesome-solid-code:](https://github.com/dunossauro/fastapi-do-zero/tree/main/codigo_das_aulas/03/){ .md-button }

---

Olá a todos! Se você está chegando agora, recomendamos verificar as aulas anteriores de nosso curso "FastAPI do Zero: Criando um Projeto com Bancos de Dados, Testes e Deploy". Hoje, vamos mergulhar no SQLAlchemy e no Alembic, e começaremos a configurar nosso banco de dados.

Antes de mergulharmos na instalação e configuração, vamos esclarecer alguns conceitos.

### O que é um ORM e por que usamos um?

ORM significa Mapeamento Objeto-Relacional. É uma técnica de programação que vincula (ou mapeia) objetos a registros de banco de dados. Em outras palavras, um ORM permite que você interaja com seu banco de dados, como se você estivesse trabalhando com objetos Python.

O SQLAlchemy é um exemplo de ORM. Ele permite que você trabalhe com bancos de dados SQL de maneira mais natural aos programadores Python. Em vez de escrever consultas SQL cruas, você pode usar métodos e atributos Python para manipular seus registros de banco de dados.

Mas por que usaríamos um ORM? Aqui estão algumas razões:

- Abstração de banco de dados: ORMs permitem que você mude de um tipo de banco de dados para outro com poucas alterações no código.

- Segurança: ORMs geralmente lidam com escapar de consultas e prevenir injeções SQL, um tipo comum de vulnerabilidade de segurança.

- Eficiência no desenvolvimento: ORMs podem gerar automaticamente esquemas, realizar migrações e outras tarefas que seriam demoradas para fazer manualmente.

### Configurações de ambiente e as 12 fatores

Uma boa prática no desenvolvimento de aplicações é separar as configurações do código. Configurações, como credenciais de banco de dados, são propensas a mudanças entre ambientes diferentes (como desenvolvimento, teste e produção). Misturá-las com o código pode tornar o processo de mudança entre esses ambientes complicado e propenso a erros.

??? tip "Caso queira saber mais sobre 12 fatores"
	Temos uma live focada nesse assunto com a participação especial do [Bruno Rocha](https://twitter.com/rochacbruno){:target="_blank"}

	![type:video](https://www.youtube.com/embed/DA-hOskxOxE)

	[:fontawesome-brands-youtube: Link direto](https://www.youtube.com/watch?v=DA-hOskxOxE){ .md-button }

Além disso, expor credenciais de banco de dados e outras informações sensíveis no código-fonte é uma prática de segurança ruim. Se esse código fosse comprometido, essas informações poderiam ser usadas para acessar e manipular seus recursos.

Por isso, usaremos o `pydantic-settings` para gerenciar nossas configurações de ambiente. A biblioteca permite que você defina configurações em arquivos separados ou variáveis de ambiente e acesse-as de uma maneira estruturada e segura em seu código.

Isso está alinhado com a metodologia dos 12 fatores, um conjunto de melhores práticas para desenvolvimento de aplicações modernas. O terceiro fator, "Config", afirma que as configurações que variam entre os ambientes devem ser armazenadas no ambiente e não no código.


Agora que entendemos melhor esses conceitos, vamos começar instalando as bibliotecas que vamos usar. O primeiro passo é instalar o SQLAlchemy, um ORM que nos permite trabalhar com bancos de dados SQL de maneira Pythonic. Além disso, o Alembic, que é uma ferramenta de migração de banco de dados, funciona muito bem com o SQLAlchemy e nos ajudará a gerenciar as alterações do esquema do nosso banco de dados.

```shell title="$ Execução no terminal!"
poetry add sqlalchemy
```

Além disso, para evitar a escrita de configurações do banco de dados diretamente no código-fonte, usaremos o `pydantic-settings`. Este pacote nos permite gerenciar as configurações do nosso aplicativo de uma maneira mais segura e estruturada.

```shell title="$ Execução no terminal!"
poetry add pydantic-settings
```

Agora estamos prontos para mergulhar na configuração do nosso banco de dados! Vamos em frente.

## O básico sobre SQLAlchemy

SQLAlchemy é uma biblioteca Python versátil, concebida para intermediar a interação entre Python e bancos de dados relacionais, como MySQL, PostgreSQL e SQLite. A biblioteca é constituída por duas partes principais: o Core e o ORM (Object Relational Mapper).

- **Core**: O Core do SQLAlchemy disponibiliza uma interface SQL abstrata, que possibilita a manipulação de bancos de dados relacionais de maneira segura, alinhada com as convenções do Python. Através do Core, é possível construir, analisar e executar instruções SQL, além de conectar-se a diversos tipos de bancos de dados utilizando a mesma API.

- **ORM**: ORM, ou Mapeamento Objeto-Relacional, é uma técnica que facilita a comunicação entre o código orientado a objetos e bancos de dados relacionais. Com o ORM do SQLAlchemy, os desenvolvedores podem interagir com o banco de dados utilizando classes e objetos Python, eliminando a necessidade de escrever instruções SQL diretamente.

Além do Core e do ORM, o SQLAlchemy conta com outros componentes cruciais que serão foco desta aula, a Engine e a Session:

### Engine

A 'Engine' do SQLAlchemy é o ponto de contato com o banco de dados, estabelecendo e gerenciando as conexões. Ela é instanciada através da função `create_engine()`, que recebe as credenciais do banco de dados, o endereço de conexão (URI) e configura o pool de conexões.

### Session

Quanto à persistência de dados e consultas ao banco de dados utilizando o ORM, a Session é a principal interface. Ela atua como um intermediário entre o aplicativo Python e o banco de dados, mediada pela Engine. A Session é encarregada de todas as transações, fornecendo uma API para conduzi-las.

Agora que conhecemos a Engine e a Session, vamos explorar a definição de modelos de dados.

## Definindo os Modelos de Dados com SQLAlchemy

Os modelos de dados definem a estrutura de como os dados serão armazenados no banco de dados. No ORM do SQLAlchemy, esses modelos são definidos como classes Python que herdam de uma classe base comum. A classe base é criada a partir de `DeclarativeBase`.

Cada classe que herda da classe base é automaticamente mapeada para uma tabela no banco de dados. Adicionalmente, a classe base inclui um objeto de metadados que é uma coleção de todas as tabelas que foram declaradas. Este objeto é utilizado para gerenciar operações como criação, modificação e exclusão de tabelas.

Vamos agora definir nosso modelo `User`. No diretório `fast_zero`, crie um novo arquivo chamado `models.py`.

```shell title="$ Execução no terminal!"
touch fast_zero/models.py
```

Inclua o seguinte código no arquivo `models.py`:

```python title="fast_zero/models.py" linenums="1"
from sqlalchemy.orm import DeclarativeBase
from sqlalchemy.orm import Mapped
from sqlalchemy.orm import mapped_column


class Base(DeclarativeBase):
    pass


class User(Base):
    __tablename__ = 'users'

    id: Mapped[int] = mapped_column(primary_key=True)
    username: Mapped[str]
    password: Mapped[str]
    email: Mapped[str]
```

Aqui, `Mapped` refere-se a um atributo Python que é associado (ou mapeado) a uma coluna específica em uma tabela de banco de dados. Por exemplo, `Mapped[int]` indica que este atributo é um inteiro que será mapeado para uma coluna correspondente em uma tabela de banco de dados. Da mesma forma, `Mapped[str]` se referiria a um atributo de string que seria mapeado para uma coluna de string correspondente. Esta abordagem permite ao SQLAlchemy realizar a conversão entre os tipos de dados Python e os tipos de dados do banco de dados, além de oferecer uma interface Pythonica para a interação com o banco de dados.


## Testando as Tabelas

Ao desenvolver software, é uma boa prática criar testes para cada nova funcionalidade implementada. Após a criação do nosso modelo de usuário, precisamos garantir seu funcionamento conforme esperado. Para isso, vamos criar dois arquivos de teste: `conftest.py` e `test_db.py`.

O arquivo `conftest.py` é utilizado pelo pytest para definir preparativos necessários antes da execução dos testes ou configurações comuns a diversos testes. Ele centraliza as chamadas para as fixtures.

??? info "Se fixtures são uma novidade para você"
	Existe uma live de Python onde discutimos especificamente sobre fixtures
	![type:video](https://www.youtube.com/embed/sidi9Z_IkLU)

	[:fontawesome-brands-youtube: Link direto ](https://youtu.be/sidi9Z_IkLU){ .md-button }

Por sua vez, o arquivo `test_db.py` será onde escreveremos os testes para nosso modelo de usuário. Isso ajudará a garantir que nossas tabelas estejam sendo criadas corretamente e que possam armazenar e recuperar informações conforme esperado.

Para criar esses arquivos, execute o seguinte comando:

```shell title="$ Execução no terminal!"
touch tests/test_db.py
touch tests/conftest.py
```

### Antes de Escrever os Testes

A essa altura, se estivéssemos buscando apenas cobertura, poderíamos simplesmente testar utilizando o modelo, e isso seria suficiente. No entanto, queremos verificar se toda a nossa interação com o banco de dados ocorrerá com sucesso. Isso inclui saber se os tipos de dados na tabela foram mapeados corretamente, se é possível interagir com o banco de dados, se o ORM está estruturado adequadamente com a classe base. Precisamos garantir que todo esse esquema funcione.

```mermaid
graph
  A[Aplicativo Python] -- utiliza --> B[SQLAlchemy ORM]
  B -- fornece --> D[Session]
  D -- interage com --> C[Modelos]
  C -- mapeados para --> G[Tabelas no Banco de Dados]
  D -- depende de --> E[Engine]
  E -- conecta-se com --> F[Banco de Dados]
  C -- associa-se a --> H[Metadata]
  H -- mantém informações de --> G[Tabelas no Banco de Dados]
```

Portanto, criaremos uma fixture para que possamos usar todo esse esquema sempre que necessário.

### Criando uma Fixture para o Banco de Dados

No arquivo `conftest.py`, vamos introduzir uma fixture chamada "session" aos nossos testes pytest. Uma fixture é uma função que permite definir e reutilizar configurações de preparação para testes ou outras funções. Elas são úteis quando se tem partes do código que precisam ser reutilizadas em vários testes.

As fixtures são declaradas com a anotação `@pytest.fixture`. Uma vez declarada, a fixture pode ser injetada em funções de teste, métodos de classe de teste, outras fixtures ou até mesmo módulos, passando-as como parâmetros.

Vamos criar uma fixture para a conexão com o banco de dados chamada `session`:

```python title="tests/conftest.py" linenums="1"
import pytest
from sqlalchemy import create_engine, select
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import StaticPool

from fast_zero.models import Base


@pytest.fixture
def session():
    engine = create_engine(
        'sqlite:///:memory:',
        connect_args={'check_same_thread': False},
        poolclass=StaticPool,
    )
    Session = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    Base.metadata.create_all(engine)
    yield Session()
    Base.metadata.drop_all(engine)
```

Aqui, estamos utilizando o SQLite como o banco de dados em memória para os testes. Essa é uma prática comum em testes unitários, pois a utilização de um banco de dados em memória é mais rápida do que um banco de dados persistido em disco. Com o SQLite em memória, podemos criar e destruir bancos de dados facilmente, o que é útil para isolar os testes e garantir que os dados de um teste não afetem outros testes. Além disso, não precisamos nos preocupar com a limpeza dos dados após a execução dos testes, já que o banco de dados em memória é descartado quando o programa é encerrado.

O que cada linha da fixture faz?

1. `create_engine('sqlite:///:memory:', connect_args={'check_same_thread': False}, poolclass=StaticPool)`: cria um mecanismo de banco de dados SQLite em memória usando SQLAlchemy. Este mecanismo será usado para criar uma sessão de banco de dados para nossos testes. Usamos `connect_args={'check_same_thread': False}` devido a algumas limitações do SQLite quando usado em threads diferentes. E `poolclass=StaticPool` para que a mesma conexão seja reutilizada durante todo o teste.

2. `Session = sessionmaker(autocommit=False, autoflush=False, bind=engine)`: cria uma fábrica de sessões para criar sessões de banco de dados para nossos testes. Definimos `autocommit=False` para controlar quando as transações são commitadas e `autoflush=False` para que SQLAlchemy não tente automaticamente sincronizar o estado da sessão com o banco de dados a cada operação.

3. `Base.metadata.create_all(engine)`: cria todas as tabelas no banco de dados de teste antes de cada teste que usa a fixture `session`.

4. `yield Session()`: fornece uma instância de Session que será injetada em cada teste que solicita a fixture `session`. Essa sessão será usada para interagir com o banco de dados de teste.

5. `Base.metadata.drop_all(engine)`: após cada teste que usa a fixture `session`, todas as tabelas do banco de dados de teste são eliminadas, garantindo que cada teste seja executado contra um banco de dados limpo.

Resumindo, essa fixture está configurando e limpando um banco de dados de teste para cada teste que o solicita, assegurando que cada teste seja isolado e tenha seu próprio ambiente limpo para trabalhar. Isso é uma boa prática em testes de unidade, já que queremos que cada teste seja independente e não afete os demais.

### Criando um Teste para a Nossa Tabela

Agora, no arquivo `test_db.py`, vamos escrever um teste para a criação de um usuário. Este teste adiciona um novo usuário ao banco de dados, faz commit das mudanças, e depois verifica se o usuário foi devidamente criado consultando-o pelo nome de usuário. Se o usuário foi criado corretamente, o teste passa. Caso contrário, o teste falha, indicando que há algo errado com nossa função de criação de usuário.

```python title="tests/test_db.py" linenums="1"
from sqlalchemy import select
from fast_zero.models import User


def test_create_user(session):
    new_user = User(username='alice', password='secret', email='teste@test')
    session.add(new_user)
    session.commit()

    user = session.scalar(select(User).where(User.username == 'alice'))

    assert user.username == 'alice'
```

### Executando o teste

A execução de testes é uma parte vital do desenvolvimento de qualquer aplicação. Os testes nos ajudam a identificar e corrigir problemas antes que eles se tornem mais sérios. Eles também fornecem a confiança de que nossas mudanças não quebraram nenhuma funcionalidade existente. No nosso caso, vamos executar os testes para validar nossos modelos de usuário e garantir que eles estejam funcionando como esperado.

Para executar os testes, digite o seguinte comando:

```shell title="$ Execução no terminal!"
task test

# ...

tests/test_app.py::test_root_deve_retornar_200_e_ola_mundo PASSED
tests/test_app.py::test_create_user PASSED
tests/test_app.py::test_read_users PASSED
tests/test_app.py::test_update_user PASSED
tests/test_app.py::test_delete_user PASSED
tests/test_db.py::test_create_user PASSED

---------- coverage: platform linux, python 3.11.3-final-0 -----------
Name                    Stmts   Miss  Cover
-------------------------------------------
fast_zero/__init__.py       0      0   100%
fast_zero/app.py           28      2    93%
fast_zero/models.py        11      0   100%
fast_zero/schemas.py       15      0   100%
-------------------------------------------
TOTAL                      54      2    96%
```

Neste caso, podemos ver que todos os nossos testes passaram com sucesso. Isso significa que nossa funcionalidade de criação de usuário está funcionando corretamente e que nosso modelo de usuário está sendo corretamente persistido no banco de dados.

Com nossos modelos e testes de banco de dados agora em ordem, estamos prontos para avançar para a próxima fase de configuração de nosso banco de dados e gerenciamento de migrações.

## Configuração do ambiente do banco de dados

Por fim, vamos configurar nosso banco de dados. Primeiro, vamos criar um novo arquivo chamado `settings.py` dentro do diretório `fast_zero`. Aqui, usaremos o Pydantic para criar uma classe `Settings` que irá pegar as configurações do nosso arquivo `.env`.

```shell title="$ Execução no terminal!"
touch fast_zero/settings.py
```

No arquivo `settings.py`, a classe `Settings` é definida como:

```python title="fast_zero/settings.py"
from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file='.env', env_file_encoding='utf-8'
    )

    DATABASE_URL: str
```

Agora, vamos definir o `DATABASE_URL` no nosso arquivo de ambiente `.env`. Crie o arquivo na raiz do projeto e adicione a seguinte linha:

```shell title=".env"
DATABASE_URL="sqlite:///database.db"
```

Com isso, quando a classe `Settings` for instanciada, ela irá automaticamente carregar as configurações do arquivo `.env`.

Finalmente, adicione o arquivo de banco de dados, `database.db`, ao `.gitignore` para garantir que não seja incluído no controle de versão. Adicionar informações sensíveis ou arquivos binários ao controle de versão é geralmente considerado uma prática ruim.

```shell title="$ Execução no terminal!"
echo 'database.db' >> .gitignore
```

## Instalando o Alembic e Criando a Primeira Migração

Antes de avançarmos, é importante entender o que são migrações de banco de dados e por que são úteis. As migrações são uma maneira de fazer alterações ou atualizações no banco de dados, como adicionar uma tabela ou uma coluna a uma tabela, ou alterar o tipo de dados de uma coluna. Elas são extremamente úteis, pois nos permitem manter o controle de todas as alterações feitas no esquema do banco de dados ao longo do tempo. Elas também nos permitem reverter para uma versão anterior do esquema do banco de dados, se necessário.

??? tip "Caso nunca tenha trabalhado com Migrações"
	Temos uma live de Python focada nesse assunto em específico

	![type:video](https://www.youtube.com/embed/yQtqkq9UkDA)

	[:fontawesome-brands-youtube: Link direto](https://youtu.be/yQtqkq9UkDA){ .md-button }

Agora, vamos começar instalando o Alembic, que é uma ferramenta de migração de banco de dados para SQLAlchemy. Usaremos o Poetry para adicionar o Alembic ao nosso projeto:

```shell title="$ Execução no terminal!"
poetry add alembic
```

Após a instalação do Alembic, precisamos iniciá-lo em nosso projeto. O comando de inicialização criará um diretório `migrations` e um arquivo de configuração `alembic.ini`:

```shell title="$ Execução no terminal!"
alembic init migrations
```

Com isso, a estrutura do nosso projeto sofre algumas alterações e novos arquivos são criados:

```plaintext hl_lines="3 9-13"
.
├── .env
├── alembic.ini
├── fast_zero
│  ├── __init__.py
│  ├── app.py
│  ├── models.py
│  └── schemas.py
├── migrations
│  ├── env.py
│  ├── README
│  ├── script.py.mako
│  └── versions
├── poetry.lock
├── pyproject.toml
├── README.md
└── tests
   ├── __init__.py
   ├── conftest.py
   ├── test_app.py
   └── test_db.py
```

No arquivo `alembic.ini`: ficam as configurações gerais das nossas migrações. Na pasta `migrations` foram criados um arquivo chamado `env.py`, esse arquivo é responsável por como as migrações serão feitas e o arquivo `script.py.mako` é um template para as novas migrações.

### Criando uma migração automática

Com o Alembic devidamente instalado e iniciado, agora é o momento de gerar nossa primeira migração. Mas, antes disso, precisamos garantir que o Alembic consiga acessar nossas configurações e modelos corretamente. Para isso, vamos fazer algumas alterações no arquivo `migrations/env.py`.

Neste arquivo, precisamos:

1. Importar as `Settings` do nosso arquivo `settings.py` e a `Base` dos nossos modelos.
2. Configurar a URL do SQLAlchemy para ser a mesma que definimos em `Settings`.
3. Verificar a existência do arquivo de configuração do Alembic e, se presente, lê-lo.
4. Definir os metadados de destino como `Base.metadata`, que é o que o Alembic utilizará para gerar automaticamente as migrações.

O arquivo `migrations/env.py` modificado ficará assim:

```python title="migrations/env.py"
from logging.config import fileConfig
from alembic import context
from fast_zero.settings import Settings
from fast_zero.models import Base

config = context.config
config.set_main_option('sqlalchemy.url', Settings().DATABASE_URL)

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

target_metadata = Base.metadata
```

Feitas essas alterações, estamos prontos para gerar nossa primeira migração automática. O Alembic é capaz de gerar migrações a partir das mudanças detectadas nos nossos modelos do SQLAlchemy.

Para criar a migração, utilizamos o seguinte comando:

```shell title="$ Execução no terminal!"
alembic revision --autogenerate -m "create users table"
```

Este comando instrui o Alembic a criar uma nova revisão de migração no diretório `migrations/versions`. A revisão gerada conterá os comandos SQL necessários para aplicar a migração (criar a tabela de usuários) e para reverter essa migração, caso seja necessário.

## Analisando a migração automática

Ao criar uma migração automática com o Alembic, um arquivo é gerado dentro da pasta `migrations/versions`. O nome deste arquivo começa com um ID de revisão (um hash único gerado pelo Alembic), seguido por uma breve descrição que fornecemos no momento da criação da migração, neste caso, `create_users_table`.

Vamos analisar o arquivo de migração:

```python title="migrations/versions/e018397cecf4_create_users_table.py"
"""create users table

Revision ID: e018397cecf4
Revises: 
Create Date: 2023-07-13 03:43:03.730534

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = 'e018397cecf4'
down_revision = None
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('users',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('username', sa.String(), nullable=False),
    sa.Column('password', sa.String(), nullable=False),
    sa.Column('email', sa.String(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('users')
    # ### end Alembic commands ###
```

Esse arquivo descreve as mudanças a serem feitas no banco de dados. Ele usa a linguagem core do SQLAlchemy, que é mais baixo nível que o ORM. As funções `upgrade` e `downgrade` definem, respectivamente, o que fazer para aplicar e para desfazer a migração. No nosso caso, a função `upgrade` cria a tabela 'users' com os campos que definimos em `fast_zero/models.py`e a função `downgrade` a remove.

Apesar desta migração ter sido criada, ela ainda não foi aplicada ao nosso banco de dados. No entanto, o Alembic já criou um arquivo `database.db`, conforme especificamos no arquivo `.env` e que foi lido pela classe `Settings` do Pydantic. Além disso, ele criou uma tabela `alembic_version` no banco de dados para controlar as versões das migrações que foram aplicadas.

```sql title="$ Execução no terminal!"
sqlite3 database.db 
SQLite version 3.42.0 2023-05-16 12:36:15
Enter ".help" for usage hints.
sqlite> .schema
CREATE TABLE alembic_version (
	version_num VARCHAR(32) NOT NULL, 
	CONSTRAINT alembic_version_pkc PRIMARY KEY (version_num)
);
sqlite> .exit
```

Para aplicar as migrações, usamos o comando `upgrade` do CLI Alembic. O argumento `head` indica que queremos aplicar todas as migrações que ainda não foram aplicadas:

```shell title="$ Execução no terminal!"
alembic upgrade head
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> e018397cecf4, create users table
```

Agora, se examinarmos nosso banco de dados novamente, veremos que a tabela users foi criada:

```sql
sqlite3 database.db 
SQLite version 3.42.0 2023-05-16 12:36:15
Enter ".help" for usage hints.
sqlite> .schema
CREATE TABLE alembic_version (
	version_num VARCHAR(32) NOT NULL, 
	CONSTRAINT alembic_version_pkc PRIMARY KEY (version_num)
);
CREATE TABLE users (
	id INTEGER NOT NULL, 
	username VARCHAR NOT NULL, 
	password VARCHAR NOT NULL, 
	email VARCHAR NOT NULL, 
	PRIMARY KEY (id)
);
sqlite> .exit
```

Finalmente, lembre-se de que todas essas mudanças que fizemos só existem localmente no seu ambiente de trabalho até agora. Para que sejam compartilhadas com outras pessas, precisamos fazer commit dessas mudanças no nosso sistema de controle de versão.

## Commit

Primeiro, vamos verificar o status do nosso repositório para ver as mudanças que fizemos:

```shell title="$ Execução no terminal!"
git status
```

Você verá uma lista de arquivos que foram modificados ou adicionados. As alterações devem incluir os arquivos de migração que criamos, bem como quaisquer alterações que fizemos em nossos arquivos de modelo e configuração.

Em seguida, vamos adicionar todas as mudanças ao próximo commit:

```shell title="$ Execução no terminal!"
git add .
```

Agora, estamos prontos para fazer o commit das nossas alterações. Vamos fornecer uma mensagem de commit que descreve as mudanças que fizemos:

```shell title="$ Execução no terminal!"
git commit -m "Adicionada a primeira migração com Alembic. Criada tabela de usuários."
```

Finalmente, vamos enviar as mudanças para o repositório remoto:

```shell title="$ Execução no terminal!"
git push
```

E pronto! As mudanças que fizemos foram salvas no histórico do Git e agora estão disponíveis no git.


## Conclusão 

Nesta aula, demos passos significativos para preparar nosso projeto FastAPI para interagir com um banco de dados. Começamos definindo nosso primeiro modelo de dados, o `User`, utilizando o SQLAlchemy. Além disso, em conformidade com as práticas de Desenvolvimento Orientado por Testes (TDD), implementamos um teste para assegurar que a funcionalidade de criação de um novo usuário no banco de dados esteja operando corretamente.

Avançamos para configurar o ambiente de desenvolvimento, onde estabelecemos um arquivo `.env` para armazenar nossa `DATABASE_URL` e ajustamos o SQLAlchemy para utilizar essa URL. Complementarmente, incluímos o arquivo do banco de dados ao `.gitignore` para evitar que seja rastreado pelo controle de versão.

Na última parte desta aula, focamos na instalação e configuração do Alembic, uma ferramenta de migração de banco de dados para SQLAlchemy. Usando o Alembic, criamos nossa primeira migração que, automaticamente, gera o esquema do banco de dados a partir dos nossos modelos SQLAlchemy.

Com esses passos, nosso projeto está bem encaminhado para começar a persistir dados. Na próxima aula, avançaremos para a fase crucial de conectar o SQLAlchemy aos endpoints do nosso projeto. Isso permitirá a realização de operações de CRUD nos nossos usuários diretamente através da API.
